{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before submitting\n",
    "1. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "2. Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\n",
    "\n",
    "4. Please submit only the `*.ipynb` file.\n",
    "\n",
    "5. Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Edit only between `YOUR CODE HERE` and `END YOUR CODE`.\n",
    "\n",
    "6. Make sure to use Python 3, not Python 2.\n",
    "\n",
    "Fill your group name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPNAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1 Poisson distribution (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement Poisson PDF checking all of the input arguments using e.g Python **_assert_** function.\n",
    "\n",
    "$$\\large{\n",
    "\\text{Poisson}(k | \\lambda) = \\frac{1}{k!}\\lambda^{k}\\exp{(-\\lambda)},\\ \\text{where}\\ k \\in \\mathbb{N}_0 \\ \\text{and}\\ \\lambda \\in \\mathbb{R}^{+}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import factorial\n",
    "\n",
    "def Poisson(k,lambd):\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2 (5 pts)\n",
    "\n",
    "* Depict the Poisson pdf for the given $k$ range and for the given rate values $\\lambda$.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<center>\n",
    "<img src='poisson.png' width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(0,21).astype(np.int)\n",
    "lambdas = [1,2,4,8,12]\n",
    "for l in lambdas:\n",
    "    #YOUR CODE HERE\n",
    "plt.grid(axis='x')\n",
    "plt.xticks(k)\n",
    "plt.ylabel('pdf')\n",
    "plt.xlabel('k')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3 Exponential family form (5 pts)\n",
    "<hr>\n",
    "* Show that the Poisson distribution is in exponential family and can be represented in a form\n",
    "\n",
    "$$\\large{\\text{Poisson}(k | \\lambda) = p(k | \\eta) = h(k)g(\\eta)\\exp{(\\eta^{\\top}u(k))}}$$\n",
    "<br>\n",
    "$\\text{YOUR ANSWER HERE}$\n",
    "\n",
    "$\\large{\n",
    "\\eta = ?\n",
    "}$\n",
    "<br>\n",
    "$\\large{\n",
    "h(k) = ? \n",
    "}$\n",
    "<br>\n",
    "$\\large{\n",
    "g(\\eta) = ?\n",
    "}$\n",
    "<br>\n",
    "$\\large{\n",
    "u(k) = ?\n",
    "}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4 Higher moments (5 Pts)\n",
    "<hr>\n",
    "\n",
    "Given that $\\large{k \\sim \\text{Poisson}(k | \\lambda)}$\n",
    "\n",
    "* Show that $\\large{\\mathbb{E}[k] = \\mathbb{E}[k^2] = \\cdots \\mathbb{E}[k^N] = \\lambda}$ using following property of an exponential family distribution:\n",
    "\n",
    "<br>\n",
    "$$\\boxed{\\large{\\mathbb{E}[u^n(k)] = - \\triangledown^n_{\\eta} \\ln{g(\\eta)}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Gauss - Gauss conjugacy (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Given that the model distributon is Gaussian with known variance $\\large{\\sigma^2 = 1}$\n",
    "\n",
    "$$\\large{\n",
    "p(x_i | \\mu, \\sigma^2=1) = \\mathcal{N}(x_i | \\mu, 1) = \\frac{1}{\\sqrt{2\\pi}}\\exp{\\Big(-\\frac{(x_i - \\mu)^2}{2}\\Big)}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show that the log of the data likelihood $\\large{\\mathcal{D} = \\{x_0,x_1,\\dots, x_n \\}}$ can be expressed as function of $\\large{\\mu}$ as following:\n",
    "\n",
    "<br> \n",
    "$$\\large{ \n",
    "\\text{YOUR ANSWER HERE}\n",
    "}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large{\n",
    "\\ln{p(D|\\mu)} = -\\frac{1}{2}\\Big(- 2\\sum_{i=1}^N x_i\\mu  + N\\mu^2 \\Big) + \\text{const}  \n",
    "}$$\n",
    "\n",
    "* Where $\\large{\\text{const}}$ utilizes all of the term which do not depend on $\\large{\\mu}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Log posterior form (5 pts)\n",
    " \n",
    "*  Given that prior distribution over mean value $\\large{\\mu}$ is Gaussian with $\\large{\\mu_0}$ and variance $\\large{\\sigma_0^2 = \\frac{1}{\\tau_0}}$ \n",
    "\n",
    "$$\\large{\n",
    "p(\\mu \\ |\\  \\mu_0, \\sigma^2 = \\frac{1}{\\tau_0} ) = \\mathcal{N}(\\mu \\  | \\ \\mu_0, \\frac{1}{\\tau_0})\n",
    "}$$\n",
    "\n",
    "* Show that the log posterior can be expressed as a function of $\\large\\mu$ in the form:\n",
    "\n",
    "<br>\n",
    "$$\\large{\n",
    "\\text{YOUR ANSWER HERE}\n",
    "}$$\n",
    "<br>\n",
    "$$\\large{\n",
    "\\ln p(\\mu |X, \\mu_0, \\tau_0) = -\\frac{1}{2}\\Big( (N + \\tau_0)\\mu^2 -2(\\sum_{i=1}^N x_i + \\tau_0\\mu_0)\\mu\\Big) + \\text{const}\n",
    "}$$\n",
    "\n",
    "$\\textbf{Note:}\\ \\boxed{\\large{ \\ln p(\\theta | X) = \\ln(X|\\theta) + \\ln p(\\theta) + \\text{const}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Gauss posterior (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the posterior in the log-space and show that it's Gaussinan with parameters $\\large{\\hat{\\mu}}$ and $\\large{\\hat{\\sigma}^2}$\n",
    "\n",
    "<br>\n",
    "$$\\large{\n",
    "\\text{YOUR ANSWER HERE}\n",
    "}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\large{p(\\mu | \\mathcal{D}, \\mu_0, \\tau_0) = \\mathcal{N}(\\mu | \\hat{\\mu}, \\hat{\\sigma}^2), \\quad \\text{where} \\\\ \\boxed{\\hat{\\mu} = ? \\quad \\hat{\\sigma}^2 = ?}\n",
    "}$$\n",
    "\n",
    "\n",
    "$\\textbf{Hint:}\\ $ You may use the square completion trick in order to get the \"right\" distribution form.\n",
    "\n",
    "* Square completion:\n",
    "$$\\large{\n",
    "ax^2 -2bx  = a(x^2 -2 \\Big(\\frac{b}{a}\\Big)x + \\Big(\\frac{b}{a}\\Big)^2 - \\Big(\\frac{b}{a}\\Big)^2) = \\frac{(x -  \\frac{b}{a})^2}{a^{-1}} + c, \\quad c = -\\frac{b^2}{a}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Toy data generation (5 pts) \n",
    "\n",
    "* Generate **20** toy data points $X_{tr}$ from univariate Gaussian distribution with $\\large{\\mu_{\\text{true}} = 5}$ and variance $\\large{\\sigma^2=1}$\n",
    "\n",
    "* Depict your generated date as a one-dimensional sample plot and a histogramm with 10 bins.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<center>\n",
    "<img src='smpl.png' widht=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_mu = 5\n",
    "np.random.seed(42)\n",
    "\n",
    "X_tr = #YOUR CODE HERE\n",
    "\n",
    "f, axs = plt.subplots(1, 2, sharex=True, figsize = (10,2))\n",
    "\n",
    "ax = axs[0]\n",
    "#YOUR CODE HERE\n",
    "\n",
    "ax.set_xlim(2,8)\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('X')\n",
    "ax.set_title('1-dim samples')\n",
    "\n",
    "ax = axs[1]\n",
    "#YOUR CODE HERE\n",
    "\n",
    "ax.set_title('Histogramm')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_yticks(np.arange(0,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 Posterior PDF (5 pts)\n",
    "\n",
    "* Implement posterior Gaussian PDF using **_norm_** function from _scipy.stats_ package (already imported).\n",
    "\n",
    "\n",
    "* Your **post_normal** functions should return computed pdf, mu_hat and sigma2_hat values from the posterior distibution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def post_normal(X, X_tr, mu_0, tau_0):\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: posterior plot (10 pts)\n",
    "\n",
    "* Compute the posterior PDF for the given space range. \n",
    "\n",
    "\n",
    "* Use empirical mean of the generated data $X_{tr}$ as $\\mu_0$ and 1 for precision $\\tau_0$ \n",
    "\n",
    "* Depict the posterior together with the Bayes estimator and twice the variance area.\n",
    "\n",
    "Your plot should look like:\n",
    "<center>\n",
    "<img src='post.png' width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "space = np.linspace(4.6,5.1,100)\n",
    "var_space = np.linspace(var_min,var_max,100)\n",
    "\n",
    "mu_0 = X_tr.mean()\n",
    "tau_0 = 1\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "plt.ylim(0,10)\n",
    "plt.grid(axis='x')\n",
    "plt.title('Guassian posterior PDF')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "## Bayesian linear regression graphical model\n",
    "\n",
    "<img src='B_LR.png' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1 Linear regression generative process (10 pts)\n",
    "\n",
    "* Use $\\text{random_state} = 42$ for all of the distributions. \n",
    "\n",
    "\n",
    "* Sample $\\beta$ parameter from Gamma distibution with $\\alpha=1$ and scale = 1 using **gamma** function from _scipy.stats_ package (already imported).\n",
    "\n",
    "\n",
    "* Compute and store $\\beta^{-1}$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta parameter generation\n",
    "\n",
    "from scipy.stats import multivariate_normal, uniform, norm, gamma\n",
    "\n",
    "degree = 4\n",
    "M = degree+1\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "print(f'beta: {beta:.2f}')\n",
    "beta_inv = 1./beta\n",
    "print(f'beta_inv: {beta_inv:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Sample polynomial weights $W \\in \\mathbb{R}^{M}$ from zero-mean multivariate Gaussian distribution with covariance matrix $\\Sigma_0$ using **multivariate_normal** function from _scipy.stats_ package (already imported). Where $M$ is the model complexity equal to polynomial degree + 1. \n",
    "\n",
    "\n",
    "* Your covarince matrix is then $\\Sigma_0 = \\beta^{-1} \\mathbb{I}_{M}$\n",
    "\n",
    "**Note:** Initial degree = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Polynomial weights generation\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "print(f\"Polynomial weights shape: {W.shape}\")\n",
    "assert W.shape[0] == M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate noise scale value $\\sigma$ from Gamma distibution with $\\alpha=2$ and scale = 1. Compute and store $\\sigma^2$ noise variance value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "sigma2  = sigma**2\n",
    "print(f'sigma2: {sigma2:0.2f}')\n",
    "\n",
    "assert sigma2 > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate $N = 25$ input data points $X \\in \\mathbb{R}^{N}$ from the uniform distribution in a range between -2 and 4.  Use **uniform** function from *scipy.stats* package.\n",
    "\n",
    "\n",
    "* Generate $R = 100$ testing data points $Z \\in \\mathbb{R}^{R}$ as a lin space between -4 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25\n",
    "R = 100\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "assert X.shape == (N,)\n",
    "assert Z.shape == (R,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute $M$ powers of all the input data $X$ and testing data $Z$ and store them in variables called $X_{\\text{pow}} \\in \\mathbb{R}^{N,M}$ and $Z_{\\text{pow}} \\in \\mathbb{R}^{(R,M)} $.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "assert X_pow.shape == (N,M)\n",
    "assert Z_pow.shape == (R,M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute _truth_ function values for all of the testing points $Z$ as $f_{\\text{truth}} = Z_{\\text{pow}}W$ \n",
    "\n",
    "\n",
    "* Sample $N$ output data points from univariate Gaussian using **norm** function with scale = $\\sigma$ and mean $\\mu = X_{\\text{pow}}W $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "assert y.shape == (N,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict the sample data and the truth function.\n",
    "\n",
    "Your plot should look like:\n",
    "<center>\n",
    "<img src=\"data.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y,label='data')\n",
    "plt.ylim(-50,100)\n",
    "plt.xlim(-4,5)\n",
    "plt.grid()\n",
    "plt.title(\"Generated data\")\n",
    "plt.plot(Z,f_truth,'r--', label='groud truth')\n",
    "_=plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "### Exercise 4.2:  Data analysis with Bayesian linear reggression (10 pts)\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Load BLR.py file into your notebook in order to get access to _**BayesianLinReg**_ class.\n",
    "\n",
    "\n",
    "* Understand the functions **_fit_** and **_predict_** from the provided class.\n",
    "\n",
    "\n",
    "* Note that the constructor expects $c$ values which is a vector used as prior for the covariance matrix diagonals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run BLR.py # Execute this line in order to load the BayesianLinReg class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an object from the BayesianLinReg class with *degree* = 4, $\\ \\sigma^2$ equal to the _true_ noise variace value and $c$ values as $M-$dimensional vector of ones. \n",
    "\n",
    "\n",
    "* Fit the input data $X$ and the observations $y$ to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.ones(M)\n",
    "\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict the output generated from the Bayes estimated polynomial weights $\\hat{W}$ and the input data $X$.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='output.png' width='300'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y,label='data')\n",
    "plt.plot(Z,f_truth,'r--', label='groud truth')\n",
    "plt.plot(X, y_hat, 'g--',linewidth=3, label='Bayes est '+'$\\\\hat{y}$')\n",
    "plt.ylim(-50,100)\n",
    "plt.xlim(-4,5)\n",
    "plt.grid()\n",
    "plt.title('Bayes estimated output')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the predicted outputs as well as the variance estimators for all of the test data point $Z$ using the _**predict**_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "assert y_pred.shape == (R,)\n",
    "assert sigma2_y.shape == (R,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict the predicted values as well as the twice variance region for the predictions.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='predictive.png' widht='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Z, y_pred,'--', c='g',linewidth=3, label=f'predictive degree: {degree}')\n",
    "plt.fill_between(Z,y_pred - 2*sigma2_y, y_pred + 2*sigma2_y, color='grey', alpha=.3 , label='twice variance')\n",
    "plt.scatter(X, y)\n",
    "plt.plot(Z,f_truth,'r--', label='groud truth')\n",
    "plt.plot(X, y_hat, 'g--')\n",
    "plt.ylim(-50,100)\n",
    "plt.title('Predicted output with the variance regions')\n",
    "plt.xlim(-4,5)\n",
    "plt.grid()\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3 Bayesian model selection (5 pts)\n",
    "\n",
    "* Perform Bayesian model selection using **_energy_** fuction from the BayesianLinReg class for different polynomial degrees in a range from 1 to 7.\n",
    "\n",
    "\n",
    "* Store energy values for all of the degrees.\n",
    "\n",
    "\n",
    "* Find the lowest energy value and the corresponding degree.\n",
    "\n",
    "\n",
    "* Depict all of the energies.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='nrg.png' width=300>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(1,8)\n",
    "energies = []\n",
    "for d in degrees:\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees, energies, 'gs--',label='free nrg')\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "min_degree = min_idx + 1\n",
    "plt.title(\"Bayesian model selection\")\n",
    "plt.axvline(min_degree, color='k', label=f\"lowest free nrg: {min_nrg}\")\n",
    "plt.grid(axis='x')\n",
    "plt.xlabel('polynomial degree')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr>\n",
    "\n",
    "## Epirical Bayesian learning (hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1 Bayesian free energy as a function of the hyperparameters (5 pts)\n",
    "\n",
    "\n",
    "* Implement function which computes the Bayesian free energy as a function of the noise variance $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_sigma2(sigma2, degree, c):\n",
    "    \n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement function which computes the Bayesian free energy as a function of the covariance matrix diagonals $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_c(c, degree, sigma2):\n",
    "    \n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2 Empirical Bayes optimization (5 pts)\n",
    "\n",
    "* Implement a function which numerically finds the lowes energy as function of noise variance $\\sigma^2$ and then as function of covariance diagonals $c$ for the given degree.\n",
    "\n",
    "\n",
    "* For numeric optimization use **minimize** function from the _scipy.optimize_ package (already imported)\n",
    "\n",
    "\n",
    "* Your function should perform the optimization, iterativelly, at least 10 times using the best $\\sigma^2$ and $c$ estimators from the previous steps.\n",
    "\n",
    "\n",
    "* Best _BayesianLinReg_ model object is returned.\n",
    "\n",
    "\n",
    "* Use the L-BFGS-B method for the numerical optimizatio with the bounds (0.01, 100) for all of the variables.\n",
    "\n",
    "\n",
    "* You may decrease the optimization tolerance to 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def empirical(degree, n_max = 10):\n",
    "    sigma2_opt=1\n",
    "    c_opt = np.ones(degree+1)\n",
    "    for i in range(n_max):\n",
    "        bnds = ((0.01,100),)\n",
    "        args = (degree,c_opt)\n",
    "        res = #YOUR CODE HERE\n",
    "        \n",
    "        sigma2_opt = res['x'][0]\n",
    "\n",
    "        bnds = np.array([[0.01,100]]*(degree+1))\n",
    "        args = (degree,sigma2_opt)\n",
    "        res = #YOUR CODE HERE\n",
    "        c_opt = res['x']\n",
    "        \n",
    "    blr = BayesiaLinReg(degree=degree, sigma2=sigma2_opt, c = c_opt)\n",
    "    return blr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Empirical Bayes model selection\n",
    "\n",
    "* Perform model selection with the energies after the empirical parameter optimization for the polynomial degrees from 1 to 7.\n",
    "\n",
    "\n",
    "* Depict the energies collected after the empirical optimizations.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='nrg_emp.png' width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = []\n",
    "models = []\n",
    "for d in degrees:\n",
    "    \n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(degrees, energies, 'gs--',label='free nrg')\n",
    "\n",
    "#YOUR CODE HERE\n",
    "\n",
    "min_degree = min_idx + 1\n",
    "plt.title(\"Bayesian model selection\")\n",
    "plt.axvline(min_degree, color='k', label=f\"lowest free nrg: {min_nrg:.2f}\")\n",
    "plt.grid(axis='x')\n",
    "plt.xlabel('polynomial degree')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the model which gives the lowest Bayes free energy after hyperparameter optimization\n",
    "\n",
    "\n",
    "* Compute and store the best output predictors $y_{\\text{pred}}$ as well as the best output variances $\\sigma^2_{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict the best predicted values as well as the twice best variance region from the model giving the lowest free energy.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='pred1.png' widht='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "plt.ylim(-50,100)\n",
    "plt.xlim(-4,5)\n",
    "plt.grid()\n",
    "plt.title('Predictive output after emp model selection')\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print the true and the best estimated noise variance\n",
    "\n",
    "\n",
    "* Try with higher number of generated data points and see how close you can get the noise variance estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"True sigma2: {sigma2:0.2f}\")\n",
    "print(f\"Estimated sigma2: {best_blr.sigma2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
