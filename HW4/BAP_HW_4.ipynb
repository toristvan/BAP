{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log, pi\n",
    "\n",
    "from scipy.stats import norm, gamma\n",
    "from scipy.special import loggamma\n",
    "\n",
    "from seaborn import kdeplot\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pymc3 as pm\n",
    "from pymc3.stats import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before submitting\n",
    "1. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "2. Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\n",
    "\n",
    "4. Please submit only the `*.ipynb` file.\n",
    "\n",
    "5. Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Edit only between `YOUR CODE HERE` and `END YOUR CODE`.\n",
    "\n",
    "6. Make sure to use Python 3, not Python 2.\n",
    "\n",
    "Fill your group name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPNAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\lrg}{\\large{}}$\n",
    "$\\newcommand{\\ltxt}[1]{\\lrg\\text{#1}}$\n",
    "$\\newcommand{\\nfr}[2]{ {}^{#1}/_{#2} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Student's T distribution (5 pts)\n",
    "\n",
    "* Implement robust studentsT pdf function\n",
    "* Ensure that the $\\nu$ and $\\sigma$ parameters are positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student's T distribution PDF\n",
    "<hr>\n",
    "$$\\lrg{\n",
    "p(x | \\mu, \\sigma, \\nu) = \\frac{\\Gamma(\\frac{\\nu + 1}{2})}{\\Gamma(\\nfr{\\nu}{2})} \\Big({\\pi\\nu\\sigma^2} \\Big)^{-\\frac{1}{2}} \\bigg( 1 + \\frac{(x - \\mu)^2}{\\nu\\sigma^2}\\bigg)^{-\\frac{\\nu +1}{2}}\n",
    "}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def studentsT(x, mu, sigma, nu):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Student's T distribution (5 pts)\n",
    "\n",
    "* Plot Stundent's T pdf for diffrent gaussianity values $\\nu$\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='stT.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10,30,100)\n",
    "\n",
    "mu = 10\n",
    "sigma = 5\n",
    "\n",
    "twos = np.array(9*[2.])\n",
    "nus = np.power(twos,np.arange(-3,6))\n",
    "\n",
    "f,axis = plt.subplots(3,3,figsize=(16,12), sharey=True)\n",
    "\n",
    "n=0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax = axis[i,j]\n",
    "        nu = nus[n]\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        n+=1\n",
    "        ax.grid(axis='x')\n",
    "        ax.legend(loc=1, fontsize=12)\n",
    "        ax.set_ylim(0,0.1)\n",
    "axis[0,1].set_title('Student\\'s T vs. Gaussian distribution', fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(X, min_val=None, max_val=None):\n",
    "    if min_val is None:\n",
    "        min_val = X.min()\n",
    "    if max_val is None:\n",
    "        max_val = X.max()\n",
    "    cNorm  = colors.Normalize(vmin=min_val, vmax=max_val)\n",
    "    cmap =  cm.ScalarMappable(norm=cNorm, cmap=cm.rainbow)\n",
    "    return cmap.to_rgba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Gamma and Normal samples (5 pts)\n",
    "\n",
    "* Draw $N=10000$ samples from Gamma distribution for the given $a$ and $b$ values\n",
    "\n",
    "\n",
    "* Compute pdf value for each of the sampled points \n",
    "\n",
    "\n",
    "* Create 1-dim data representation plot with color as pdf values and rainbow colormap\n",
    "\n",
    "\n",
    "* Depict first moment of the Gamma distribution\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='gam.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 10000\n",
    "a = 8\n",
    "b = 2\n",
    "E_lambd = a/b\n",
    "scale = 1./b\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "col = get_colors(pdfs)\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.scatter(lambdas, np.zeros(len(pdfs)), marker='|',  c=col,s=500)\n",
    "plt.axhline(0,color='k')\n",
    "plt.axvline(E_lambd,ls='--', color='g' ,ymin=0.2, ymax=0.8, linewidth=2, label='$\\\\mathbb{E}[\\\\lambda]$ ='+f'{a/b:.2}')\n",
    "plt.xlabel('$\\\\lambda$', fontsize=15)\n",
    "plt.yticks([])\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Draw $N=10000$ samples from Normal distribution for the given $\\sigma$ value.\n",
    "\n",
    "\n",
    "* Compute pdf value for each of the sampled points \n",
    "\n",
    "\n",
    "* Create 1-dim data representation plot with color as pdf values and rainbow colormap\n",
    "\n",
    "\n",
    "* Depict first moment of the Normal distribution\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='normal.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_0 = 2\n",
    "sigma =1./E_lambd**0.5\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "col = get_colors(pdfs)\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.scatter(mus, np.zeros(len(pdfs)), marker='|',  c=col,s=500)\n",
    "plt.axhline(0,color='k')\n",
    "plt.axvline(m_0,ls='--', color='g' ,ymin=0.2, ymax=0.8, linewidth=2, label='$\\\\mathbb{E}[\\\\mu]$ ='+str(m_0))\n",
    "plt.xlabel('$\\\\mu$', fontsize=15)\n",
    "plt.yticks([])\n",
    "_=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Normal-gamma PDF (5 pts)\n",
    "\n",
    "* Implement Normal-gamma distribution as a product of two pdf functions (norm and gamma) from scipy.stats package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal-gamma distribution\n",
    "\n",
    "$$\\lrg{\n",
    "p(\\mu,\\lambda| m, \\beta, a, b ) = \\text{NormGam}(\\mu,\\lambda | m,\\beta,a,b) = \\mathcal{N}(\\mu | m, (\\beta\\lambda)^{-1}) \\text{Gamma}(\\lambda| a,b)\n",
    "}$$\n",
    "\n",
    "$$\\boxed{\\lrg{\\text{NormGam}(\\mu,\\lambda | m,\\beta,a,b)=\n",
    "\\Big(\\frac{\\beta\\lambda}{2\\pi}\\Big)^{-\\frac{1}{2}}\\exp\\Big(-\\frac{\\beta\\lambda\\cdot(\\mu - m)^2}{2}\\Big) \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{(a - 1)}\\exp{(-b\\lambda)}\n",
    "}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_gamma(mu, lambd, m_0=0, beta=1, a=1, b=1):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Normal-gamma density plot (10 pts)\n",
    "\n",
    "* Create a plot of the Normal-gamma density for given $\\beta$ values within the given range\n",
    "\n",
    "* Depict different density regions as a color bar.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='col.png' width=1000>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.linspace(-6, 10, 100)\n",
    "lambdas = np.linspace(1e-2, 8, 100)\n",
    "M, L = np.meshgrid(mus, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [0.1, .25, .5]\n",
    "\n",
    "f,axis = plt.subplots(1, len(betas), figsize=(16,6), sharey=True, sharex=False)\n",
    "\n",
    "for i in range(len(betas)):\n",
    "    ax = axis[i]\n",
    "    beta = betas[i]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    ax.set_xlabel('$\\\\mu$',fontsize=15)\n",
    "    ax.set_ylabel('$\\\\lambda$',fontsize=20, rotation=0, labelpad=20)\n",
    "\n",
    "\n",
    "axis[1].set_title('Normal-gamma PDF', fontsize=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4: Normal to Normal-gamma conjugacy ( 10 pts)\n",
    "\n",
    "\n",
    "* Use random state $= 42$ for all random sampling functions in this exercise\n",
    "\n",
    "\n",
    "* Draw lambda value from Gamma distribution for given $a$ and $b$ values\n",
    "\n",
    "\n",
    "* Generate $N=25$ toy data points drown from Normal distribution with given mean $\\mu = m_0$ and scale value $\\large{\\sigma = \\frac{1}{\\sqrt\\lambda} }$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data\n",
    "N = 25\n",
    "\n",
    "m_0 = 2\n",
    "a_true = 4\n",
    "b_true = 2\n",
    "scale = 1/b_true\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f'True lambda: {lambd:.2f}')\n",
    "print(f'True sigma: {sigma:.2f}')\n",
    "print(\"True mean: \", m_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Depict your samples data as 1-dim plot together with the histogram density plot\n",
    "\n",
    "\n",
    "* Compute and depict empirical mean of your data\n",
    "\n",
    "<img src='toy.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,axis = plt.subplots(1, 2, figsize=(12,4), sharey=False, sharex=False)\n",
    "\n",
    "ax = axis[0]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ax.legend()\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax = axis[1]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ax.legend(loc=1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.5: Normal-gamma posterior (5 pts)\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "* Implement Normal-gamma posterior function as a function of $\\mu$ and $\\lambda$ for given data $X$ and hyperparameters $m_0, \\beta_0, a_0, b_0$\n",
    "\n",
    "\n",
    "\n",
    "* Your function should return computed pdf values, first moment of $\\mu$ and $\\lambda$\n",
    "\n",
    "\n",
    "\n",
    "$$\\lrg{\n",
    "p(\\mu,\\lambda | X, m_0, \\beta_0, a_0, b_0) = \\text{NormGam}(\\mu, \\lambda | m, \\beta, a, b ),\\ \\text{where}\n",
    "}$$\n",
    "\n",
    "$$\\boxed{\\lrg{\n",
    "\\beta =  \\beta_0 + N, \\quad m = \\frac{N\\overline{X} + \\beta_0m_0}{\\hat{\\beta}}, \\quad a = a_0 + \\nfr{N}{2},\\quad b = b_0 + \\frac{1}{2}\\bigg( \\sum_{n=1}^N (X_n - \\overline{X})^2 + \\frac{N\\beta_0(\\overline{X} - m_0)^2}{\\hat\\beta}\\bigg),\\\\  \\quad \\overline{X} = \\frac{1}{N}\\sum_{n=1}^N X_n\n",
    "}}$$\n",
    "\n",
    "$$\\lrg{\n",
    "\\mathbb{E}[\\mu] = m,\\quad \\mathbb{E}[\\lambda] = \\frac{a}{b}\n",
    "}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(mu, lambd, X, m_0, beta_0, a_0, b_0):\n",
    "    N = len(X)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return pdfs, Em, El"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.5: Normal-gamma posterior density (5 pts)\n",
    "\n",
    "\n",
    "* Depict Normal-gamma posterior density region for the given region as a filled countour plot\n",
    "\n",
    "\n",
    "* Depict first moments of $\\mu$ and $\\lambda$ from your posterior.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='post.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = np.linspace(1.825, 1.98, 100)\n",
    "lambdas = np.linspace(1, 4.5, 100)\n",
    "M, L = np.meshgrid(mus, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta_0 = 1\n",
    "a_0 = 4\n",
    "b_0 = 2\n",
    "xm = X.mean()\n",
    "\n",
    "fig,ax=plt.subplots(1,1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ax.set_ylabel('$\\\\hat\\lambda$', rotation=0, fontsize=15, labelpad=20)\n",
    "ax.set_xlabel('$\\\\hat\\mu$',fontsize=15)\n",
    "ax.set_title('Normal-gamma posterior')\n",
    "ax.scatter(Em,El,marker='x', color='k')\n",
    "ax.scatter(Em,El, alpha=0, label='$\\\\mathbb{E}[\\lambda]=$'+f'{El:.2f}'+'\\n'+'$\\\\mathbb{E}[\\mu] = $'+f'{Em:.2f}')\n",
    "_=ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'True lambda:\\t{lambd:.2f}\\t'+f'| Est lambda:\\t{El:.2f}')\n",
    "print(f'True sigma:\\t{sigma:.2f}\\t'+f'| Est sigma:\\t{1/El**0.5:.2f}')\n",
    "print(f\"True mean:\\t{m_0}\\t\" +f'| Est mean:\\t{Em:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Normal to Normal-gamma by sampling (10 pts)\n",
    "\n",
    "\n",
    "* Define a probabilistic model using pyMC3 package\n",
    "\n",
    "\n",
    "* Use _Gamma_ function for lambda parameter with $a = b = 1$\n",
    "\n",
    "\n",
    "* Use _Deterministic_ function to compute scale $\\sigma$\n",
    "\n",
    "\n",
    "* Use _Normal_ function for mean $\\mu$ with $mu = 0$ and $sd = 10$\n",
    "\n",
    "\n",
    "* Use _Normal_ function to define your likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_gam = pm.Model()\n",
    "\n",
    "with gauss_gam:\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Draw 10000 posterior samples from your prob model with 1000 tune steps and 4 chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with gauss_gam:\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Analysis of the posterior samples (5 pts)\n",
    "\n",
    "* Depict your collected trace with _traceplot_ function\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='trace.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show your trace summary\n",
    "\n",
    "<img src='summary.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show your posterior plot using _plot_posterior_ function\n",
    "\n",
    "<img src='p_post.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Posterior predictive approximation (5 pts)\n",
    "\n",
    "* Collect 5000 posterior samples by using _sample_posterior_predictive_ function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gauss_gam:\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create approx pedictive function as histogram density plot with kde function\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='pred.png' width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "_=plt.title('Approx posterior predictive density', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict posterior samples for $\\mu$ and $\\lambda$ as a scatter plot.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='smpl.png' width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "m_mean = \n",
    "l_mean ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Posterior density estimation (5 pts)\n",
    "\n",
    "\n",
    "* Estimate posterior density by using _gaussian_kde_ function from scipy package.\n",
    "\n",
    "\n",
    "* Depict your Normal-gamma posterior approximation as filled contour plot for the given range.\n",
    "\n",
    "Your plot should look like:\n",
    "\n",
    "<img src='kde.png' width=600>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "mus = np.linspace(1.825, 1.98, 100)\n",
    "lambdas = np.linspace(1, 4.5, 100)\n",
    "M, L = np.meshgrid(mus, lambdas)\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axis=plt.subplots(1,2, figsize=(12,8), sharex=True)\n",
    "\n",
    "ax = axis[0]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ax.scatter(Em,El,marker='x', color='k')\n",
    "ax.scatter(Em,El, alpha=0, label='$\\\\mathbb{E}[\\lambda]=$'+f'{El:.2f}'+'\\n'+'$\\\\mathbb{E}[\\mu] = $'+f'{Em:.2f}')\n",
    "ax.legend()\n",
    "\n",
    "ax = axis[1]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ax.set_title('Normal-Gamma posterior approximation')\n",
    "ax.scatter(m_mean,l_mean, color='k', marker='x', label='$\\\\mathbb{E}[\\lambda]=$'+f'{l_mean:.2f}'+'\\n'+'$\\\\mathbb{E}[\\mu] = $'+f'{m_mean:.2f}')\n",
    "_=ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Linear regression by sampling (5 pts)\n",
    "\n",
    "\n",
    "* Given $N=100$ toy data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "X = np.linspace(-2,3,N)\n",
    "f1 = np.sin\n",
    "D = f1(X) + norm.rvs(scale=0.1, size=N)\n",
    "plt.scatter(X,D,color='k', alpha=0.5, label='data')\n",
    "plt.plot(X,f1(X), 'r-', label='true f')\n",
    "_=plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define a probabilistic model using pyMC3 package\n",
    "\n",
    "\n",
    "* Use _MvNormal_ function for polynomial weights with $\\mu = 0$ and covariance matrix as 4-dimensional identity matrix.\n",
    "\n",
    "\n",
    "* User _Gamma_ function for prior over the observation noise scale value $\\sigma$.\n",
    "\n",
    "\n",
    "* Use _Normal_ function to define your likelihood.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.math import dot\n",
    "\n",
    "H = 4 \n",
    "X_pow = X[:,None]**np.arange(H)[None]\n",
    "X_pow.shape\n",
    "\n",
    "reg = pm.Model()\n",
    "\n",
    "with reg:\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collect $5000$ posterior samples with 1000 tuning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with reg:\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print sampled trace summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict your traceplot\n",
    "\n",
    "<img src='tp.png' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Analysis of the posteror samples (5 pts)\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Depict your predicted function together with the true function and all data points\n",
    "\n",
    "<img src='predf.png' width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "plt.plot(X,y_p,'b--', label='predicted f')\n",
    "plt.scatter(X,D,color='k', alpha=0.5, label='data')\n",
    "plt.plot(X,f1(X), 'r-', label='true f')\n",
    "_=plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collect 1000 posterior samples by using _sample_posterior_predictive_ function\n",
    "\n",
    "\n",
    "* Depict regions of the higherst posterior density for 50%, 25% and 5% samples inside using _hpd_ function\n",
    "\n",
    "\n",
    "<img src='hpd.png' width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = np.argsort(X)\n",
    "x_ord = X[idx]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "plt.plot(X,y_p,'b--', label='predicted f')\n",
    "plt.scatter(X,D,color='k', alpha=0.5, label='data')\n",
    "plt.plot(X,f1(X), 'r-', label='true f')\n",
    "plt.title('Highest posterior predictive regions')\n",
    "_=plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Mixture of linear regressors by sampling (15 pts)\n",
    "\n",
    "* Given $N=100$ toy data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, dirichlet, multinomial\n",
    "N = 100\n",
    "X = np.sort(uniform.rvs(-6,12,N, random_state=42))\n",
    "\n",
    "f1 = lambda x : x**2\n",
    "f2 = lambda x: -x + 10\n",
    "\n",
    "theta = dirichlet.rvs([10,10], random_state=42).ravel()\n",
    "z = multinomial.rvs(1,p=theta, size = N, random_state=42)\n",
    "\n",
    "D = z[:,0]*f1(X) + z[:,1]*f2(X) + norm.rvs(scale=1, size=N, random_state=42)\n",
    "\n",
    "plt.plot(X,f1(X), 'r-')\n",
    "plt.plot(X,f2(X), 'b-')\n",
    "plt.title('Mixture of polynomials')\n",
    "_=plt.scatter(X,D,color='k', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "H = 3\n",
    "X_pow = X[:,None]**np.arange(H)[None]\n",
    "X_pow.shape,D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Define probabilistic model for mixture of polynomials\n",
    "\n",
    "\n",
    "* Use _Categorical_ function to sample mixture coefficients $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mreg = pm.Model()\n",
    "\n",
    "with mreg: \n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collect 10000 samples from posterior with 2000 tuning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with mreg:\n",
    "    \n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute and print posterior mean values for polynomial coefficients $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wp = trace['W'].mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Mixture of linear regressors predictive plot (5 pts)\n",
    "\n",
    "\n",
    "* Draw 1000 posterior predictive samples\n",
    "\n",
    "\n",
    "* Compute predictive mean and variance value for all input data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Depict predictive mean and variance values as error bar plot using _errorbar_ function\n",
    "\n",
    "<img src='p_m_var.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axis = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "ax = axis[0]\n",
    "ax.plot(X,f1(X), 'r-', label='true f1')\n",
    "ax.plot(X,f2(X), 'b-', label='true f2')\n",
    "ax.scatter(X,D,color='k', alpha=0.5, label='data')\n",
    "ax.set_ylim(ymin=-6)\n",
    "ax.legend()\n",
    "\n",
    "ax = axis[1]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(ymin=-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
